---
title: "Intro to R Workshop: Session 5"
subtitle: "UCI Data Science Initiative"
#author: "Steven Brownlee (based on Wenliang He and Sepehr Akhavan's material)"
date: Nov 18, 2016
#output: slidy_presentation
output: ioslides_presentation
# subtitle: UCI Data Science Initiative
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

## Session 5 Agenda
+ More Plotting (Line Charts)

+ Logistic Regression


## Line Charts
```{r echo=TRUE}
cars = c(2,3,4,3,5)
plot(cars, type = "o")
```


## Line Charts - Change Some Attributes
```{r echo=TRUE}
plot(cars, type="o", col="red", ylim=c(0.5,5), xlab="Months", ylab="Sales in Millions")
title(main="Autos Sales", col.main="darkgrey")
```


## Line Charts - Add Another Line
```{r echo=TRUE}
plot(cars, type="o", col="red", ylim=c(0.5,5), xlab="Months", ylab="Sales in Millions")
title(main="Autos Sales", col.main="darkgrey")
suvs = c(1,4,3,3,4)
lines(suvs, type="o", col="blue", lty=2, pch=6)
```


## Line Charts - Add a Horizontal Line
```{r echo=TRUE}
plot(cars, type="o", col="red", ylim=c(0.5,5), xlab="Months", ylab="Sales in Millions")
title(main="Autos Sales", col.main="darkgrey")
lines(suvs, type="o", col="blue", lty=2, pch=6)
abline(h=c(3,4), lty=2, col="darkgrey") # h for horizontal
```


## Line Charts - Add Legend
```{r echo=TRUE}
plot(cars, type="o", col="red", ylim=c(0.5,5), xlab="Months", ylab="Sales in Millions")
title(main="Autos Sales", col.main="darkgrey")
lines(suvs, type="o", col="blue", lty=2, pch=6)
abline(h=c(3,4), lty=2, col="darkgrey") # h for horizontal
legend(4.2, 1.2, c("cars","suvs"), col=c("red","blue"), lty=1:2, pch=c(1,6), bty="n")
```



##  Logistic Regression - Data
+ Used to model the probability of a binary outcome
+ glm() is used to fit logistic regression model
+ Mroz data - Want to predict female labor force participation

```{r echo=TRUE, error=FALSE, message=FALSE, warning=FALSE}
library(car)
data(Mroz); # load Mroz data
str(Mroz)
```


## Logistic Regression - Data Description
+ lfp: female labor-force participation; a factor with levels: no; yes.
+ k5: number of children 5 years old or younger.
+ k618: number of children 6 to 18 years old.
+ age: in years.
+ wc: wife's college attendance; a factor with levels: no; yes.
+ hc: husband's college attendance; a factor with levels: no; yes.
+ lwg: log expected wage rate; 
    + for women in the labor force, the actual wage rate; 
    + for women not in the labor force, an imputed value 
+ inc: family income exclusive of wife's income.


## Logistic Regression - Data Description
```{r echo=TRUE, error=FALSE, message=FALSE, warning=FALSE}
str(Mroz)
```


## Logistic Regression - Data Description
Barplot
```{r echo=TRUE, error=FALSE, message=FALSE, warning=FALSE}
barplot(table(Mroz$lfp), col = "blue", main = "Count of Females by Labor Force Participation",
        xlab = "Labor Force Participation Status", ylab = "Number of Females")
```


## Logistic Regression - Data Description
Stacked Barplot
```{r echo=TRUE, error=FALSE, message=FALSE, warning=FALSE}
counts <- table(Mroz$lfp, Mroz$k5)
barplot(counts, col = c("blue","red"),
        main = "Labor Force Participation by # of Children < 5",
        xlab = "# of Children < 5", ylab = "Count",
        legend = rownames(counts))
```


## Logistic Regression - Data Description
Grouped Barplot
```{r echo=TRUE, error=FALSE, message=FALSE, warning=FALSE}
counts <- table(Mroz$lfp, Mroz$k5)
barplot(counts, col = c("blue","red"),
        main = "Labor Force Participation by # of Children < 5",
        xlab = "# of Children < 5", ylab = "Count",
        legend = rownames(counts), beside = T)
```


## Logistic Regression - Data Description
Scatter Plot with Classification
```{r echo=TRUE, error=FALSE, message=FALSE, warning=FALSE}
plot(Mroz$age, Mroz$lwg, col = ifelse(Mroz$lfp == "yes", "red", "blue"),
     main = "Age vs. Log Wage by LFP", xlab = "Age (Years)", ylab = "Wage")
legend(x = 50, y = -1.5, legend = c("in LF", "Out of LF"),
       fill = c("red", "blue"), bty = "n")
```


## Logistic Regression - Model Fit
```{r echo=TRUE, error=FALSE, message=FALSE, warning=FALSE}
fitLogistic <- glm(lfp ~ k5 + age, family=binomial(logit), data=Mroz); 
fitLogistic
```


## Logistic Regression - Model Fit
```{r echo=TRUE, error=FALSE, message=FALSE, warning=FALSE}
summary(fitLogistic)
```


## Logistic Regression - Model Fit
```{r echo=TRUE, error=FALSE, message=FALSE, warning=FALSE}
names(fitLogistic)
```


## Logistic Regression - Exponentiated CIs
+ 95% CI for exp(coefficients) (profile liklihood mehtod)
```{r echo=TRUE, error=FALSE, message=FALSE, warning=FALSE}
exp(confint(fitLogistic, level=0.95))
```

+ 95% CI for exp(coefficients) (Wald confident interval)
```{r echo=TRUE, error=FALSE, message=FALSE, warning=FALSE}
exp(confint.default(fitLogistic, level=0.95))
```


## Logistic Regression - Predictions
To get Probabilities, be sure to use type = "response"
```{r echo=TRUE, error=FALSE, message=FALSE, warning=FALSE}
head(Mroz,1)
XB <- as.vector(head(predict(fitLogistic),1))
p <- as.vector(head(predict(fitLogistic, type = "response"),1))
XB
p
exp(XB)/(1 + exp(XB))
```


## Logistic Regression - Updates
+ Update model by adding 'inc' and 'lwg'
```{r echo=TRUE, error=FALSE, message=FALSE, warning=FALSE}
fitLogistic2 = update(fitLogistic, . ~ . + inc + lwg, data=Mroz)
```

+ After update
```{r echo=TRUE, error=FALSE, message=FALSE, warning=FALSE}
fitLogistic2
```


## Model Comparison
+ Use change of deviance of fitted model
```{r echo=TRUE, error=FALSE, message=FALSE, warning=FALSE}
anova(fitLogistic, fitLogistic2, test='LRT')
```





